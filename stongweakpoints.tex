\section{Strong and weak points about Neural Networks applications for Monte Carlo simulations}
\subsection{Speed, accuracy and reliability}
\label{subsec:speed}
As described in Section~\ref{subsec:interactions}, one of the main advantage of AI inspired systems, when compared to more standard simulation algorithms, is a potential speed-up without necessarily impacting performance.
The improvement comes from the nature of feed-forwards Neural Networks used at inference time, which are described as a series of matrix multiplication of fixed length\footnote{This is not strictly  valid for some types of recurrent networks, where the recurrence can introduce an indetermination in the sequence of mathematical operations.}, without access to any data structure apart from the inputs and the weights. Today's processors, from CPUs to GPUs to TPUs, are very efficient in processing matrix algebra calculations; this reflects diretly to short processing times.
In order to give quantitative examples, we can refer to the two complex GANs described in Section~\ref{subsec:interactions}, which are fed by Geant4-processed events in the training phase.
Table~\ref{tab:speed} reports on the absolute time needed to process Geant4 vs the GAN for events with similar input; the speedups are of order 100x using CPUs, and an additional factor 100x with GPUs\footnote{It can be said that it is an unfair comparison since Geant4 cannot currently use GPUs; still, it shows how AI inspired tools offer a path to the use of more performing technologies.}.
\begin{center}
\begin{tabular}{l|c|c|c}
    System & Software & Speed \\
    \hline
     Intel Xeon E5-2683 & Geant4 & ~ 1 min \\
     Nvidia RTX 1080 & 3d-GAN & 0.04 msec\\
          \hline
     AWS \verb p2.8xlarge  & Geant4 & 1.7 sec \\
     AWS \verb p2.8xlarge  & CaloGan & O(10) msec \\
     AWS \verb p2.8xlarge  + Nvidia K80 & CaloGan & O(0.01) msec
\end{tabular}
Fig~\ref{tab:speed}: Geant4 vs GAN performance under various setups, as extracted from~\cite{calogan} and~\cite{3dgan}.
\label{tab:speed}
\end{center}

\subsection{Response to unexpected (untrained) signals}
\subsection{Unphysical responses and how to impose physical constraints}
\label{subsec:physical}
AI inspired tools are a mathematical solution to problems we have problems solving algorithmically, either because too difficult or too slow.
An important difference with respect to standard "human-written" code is impossibility to impose at algorithmic level precise conservation laws, such as the conservation of energy and momentum.
There is no guarantee a ML system will conserve them, since their validity is not implemented in any explicit form.

In most of the cases shown in Section~\ref{sec:examples} the strict conservation (for example) of energy in particle showering into calorimeters does not need to be exact, since in the transfer  between the energy in the impinging particle and the final products is in any case approximate due to effects of leaking, and smoothed by the detector resolution. In cases like this, while the training tries to  match the "cell by cell" energy deposition, there is no explicit request that that the total energy deposited in the calorimeter matches the precise simulation. In principle, a loss function designed to have the minimum in when all the cells have the "expected" energy would suffice, but experience (and somehow common sense) shows that by adding to the loss function an explicit term tending to the conservation of total energy, like in Eqn. (2) in~\cite{calogan}, constrains can implemented even if not in exact form. This solution is called ``soft'' precisely for this reason. .
The relative weight of the various terms in the loss functions are somehow arbitrary, and an higher weight to the part tending to the constraint (not really imposing it!) represents the developer desire to have it more precisely maintained, even if never exactly.

A different approach, as  presented in ~\cite{salzmann}, tries to implement instead ``hard'' and exact constraints on the outputs during the training  phase, the mathematical complexity and the time needed increase, such as to advice the use of (eventually up-weighted)  ``soft'' constraints in any case.

% https://arxiv.org/pdf/1706.02025.pdf
%example from https://journals.aps.org/prd/pdf/10.1103/PhysRevD.97.014021 : eqn (2) and following