\section{Introduction to Neural Networks}
Neural Networks are a specific branch of the Artificial Intelligence (AI) domain in computer science.
They get their inspiration from the fact that humans are evidently able to fulfill complex tasks; hence, by replicating the low-level mechanisms of the human brain on computing systems, one can potentially construct high level algorithms with similar capabilities.

\subsection{The human brain}
\label{subsect:brain}
Neglecting any functional description, the human brain can be described as an organ composed by neurons, glial cells, neural stem cells and blood vessels (Figure~\ref{fig:humanbrain}).
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{images/humanbrain.png}
    \caption{A pictorial view of the human brain (from Wikipedia).}
    \label{fig:humanbrain}
    \end{subfigure}
    \hfill
        \begin{subfigure}[b]{0.55\textwidth}
        \includegraphics[width=1\textwidth]{images/Blausen_0657_MultipolarNeuron.png}
     \caption{The human neuron (from Wikipedia, by BruceBiaus, CC BY 3.0).}
     \label{fig:neuron}
        \end{subfigure}

\end{figure}
 In our current understanding, the neurons are the units performing basic "operations" within the human brain, and their aggregated response is responsible for the high-level behaviour typical of humans.
 A neuron, as sketched in Figure~\ref{fig:neuron}, is composed of three main units: a number of dendrites, the soma (the cell body), and an axion; the total size largely varies between different types of neurons; the neurons used for cognitive functions (as those in the grey matter of the brain) are usually short, XX $\mu$m.
Functionally, a neuron is able to generate an electric response on the axion (\emph{output}), depending on the electrical potential present at the synapses (\emph{inputs}) present on the dendrites. Neurons are \emph{chained} by connections between axions and dendrites, generating a mesh in which N neurons are connected via M synapses.
 The high-level response of the human brain to stimuli is understood to come from the complexity of such mesh, with a standard human brain featuring $~10^{11}$ neurons each with $~7000$ synapses, for a total of $~10^{15}$ "connections".

 In literature various models of the neuron behavior have been proposed~\cite{neuronbe1, neuronbe2, neuronbe3}, %https://en.wikipedia.org/wiki/Biological_neuron_model
 here we will focus on the simplest yet most simple to implement in computer systems~\cite{artificialneuron} (see Figure~\ref{fig:artificialneuron}): %https://en.wikipedia.org/wiki/Artificial_neuron
 
 \begin{figure}[h]
    \centering
    \hfill
        \includegraphics[width=0.9\textwidth]{images/artificialneuron.png}
     \caption{The artificial neuron.}
     \label{fig:artificialneuron}

\end{figure}
 
 in this model, the \emph{output} $y$ signal at the axion is assumed to be a function of the \emph{inputs} $x_i$ via
 \begin{equation}
   y = f(\sum_{i=1}^{N} w_i x_i)
   \label{eq:artificialneuron}
 \end{equation}
where $w_i$ are weights defined by chemical potentials at the synapses, and the function $f$ wants to model the non linearity of response of biological neurons with the \emph{inputs}; on top of this, the function $f$ is needed in the mathematical model in order to allow the description of non linear phenomena~\cite{nonlinearitytheorem}. The perceptron~\cite{perceptron}, one of the first models used in literature for Neural Networks, uses a very similar model, with a simplified $f$ function which is simply
% nonlinearitytheorem https://doi.org/10.1016/0893-6080(91)90009-T
\begin{equation}
  f(\vec{x})= \begin{cases}
                1 &  \text{if}\  \sum_{i=1}^{N} w_i x_i >0 \\
                0 &  \text{otherwise}
              \end{cases}
\end{equation}
Today, two small modifications are typical when using Neural Networks:
\begin{itemize}
\item the addition of a further synapse $x_0$ which is always 1, as a bias to the system; its weight is referred to as $x_0$ or $b$ (as in \emph{bias}).
\item the use of continuous $f$ non linear functions, as  logistic~\cite{logistic} or hyperbolic~\cite{logistic} functions.
\end{itemize}
% logistic: https://en.wikipedia.org/wiki/Logistic_function
% hyperbolic
Neural networks are designed by combining multiple neurons in \emph{networks}, usually in a layered structure: one layer is used to map the inputs, a few/many layers are \emph{hidden}, and a single layer used to to map the outputs. On top of that, more complex neurons can be used, for example including a "memory" cell, or presenting a recurrent behavior by reusing its output as one of the inputs. A full description of all the type of neurons and networks is beyond the scope of this chapter; in the following, the ones most relevant to Monte Carlo simulations will be presented with more detail. For reference, still, a complete classification of currently relevant neural networks is shown in Figure~\ref{fig:types}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/types.png}
    \caption{Types of neurons and neural networks currently relevant in literature (Copyright F. van Veen 2016).}
    \label{fig:types}
\end{figure}

As clearly visible in the figure, some network topologies have an high number of hidden layers. While the Universal Approximation Theorem~\cite{nonlinearitytheorem} states that under quite generic conditions, a single hidden layer between inputs and outputs should be enough in all cases, networks used in science during the last decade tend to be "deep" (i.e. with many hidden layers). This has multiple motivations: on one side, the theorem states that it is possible to have just one hidden layers, but does not state with how many neurons (and it tends to be a very large number); on the other side, a deep structure tend to be better human readable, with cascade sub networks with a more identifiable and logical role. Hence, relevant networks in today's science tend to be deep.

% nonlinearitytheorem     Recommended Citation
%Kawaguchi, Kiyoshi, "A multithreaded software model for backpropagation neural network applications" (2000). ETD Collection for %University of Texas, El Paso. AAIEP05411.
%https://scholarworks.utep.edu/dissertations/AAIEP05411

The typical utilization pattern for a majority of network topologies is to feed them as input a large set of data representing the problem of interest, be it a medical image, a set of features or any output from the instrumentation, and at the same time provide the "expected output" from a so-called training set. 

In the simplest type of networks, the response from the neurons in the hidden and the final layers are considered in sequence (inputs to outputs), with each layer \emph{feeding} the following layers; hence the name Feed Forward Neural Networks (FFNNs).

During the training, the network adjusts its internal free degrees of freedom (the weights $w_i^j$ in equation~\ref{eq:artificialneuron}, extended to the $j$ neurons in the various layers) to better reproduce the desired answers, via minimization procedures which can be either numerical or analytical and involves the definition of a loss function to be explicitly minimized. Typical loss function can be simple weighted differences between the networks results and "expected results", but functional forms like cross entropy and mean square errors are more typical~\cite{lossfunctions}.

What has just been described is the training process for \emph{supervised} Neural networks, which rely on an externally provided "truth" to adjust for optimal performance, without having any a-priori knowledge of the physical process they want to reproduce.
Other topologies describe instead the \emph{unsupervised} Neural Networks, in which the training process just implies the utilization of datasets without the need to provide the correct answers (which can be unknown). Examples of such networks will be provided in Section~\ref{sec:unsupervised}.

\subsection{Convolutional networks}
Convolutional networks (CNNs) are a useful subset of neural networks, which exhibit peculiar characteristics of being space invariant with respect of the inputs.

They are particularly interesting in the realm of Monte Carlo simulations, since the space invariance is a valuable characteristics: for example, a shower from an hadronic particle into a material, when far from the edges, does not depend on the specific entry point nor on its direction.
CNNs are used with success in categorization problems, where typical structures must be discovered into a set of input data: a typical example is the identification of lesions in medical imaging, trained on reported images by clinicians ~\cite{cnnmedical}, as depicted in Figure~\ref{fig:cnnsmedical}.
Technically, CNNs use basic neurons as explained in Section~\ref{subsect:brain}, with those in the hidden layers fed by small portions of the inputs per iteration, thus realizing spatial independence, for example. Multiple application of several convolutional layers drive to an overall analysis on the inputs, and to the final outputs.

\subsection{Recurrent networks}
The CNNs just described are a type of \emph{stateless} network, in which the output depends only on the inputs presented on the first layer. In Recurrent Neural Networks (RNNs), the response to a specific input feature set also depends on the history of the network, i.e. the inputs presented at prior times; as such, the network presents a sort of "memory", which can be used to correlate multiple inputs in sequence. A typical utilization pattern is in the presence of inputs of variable length, which cannot be estimated \emph{a priori}, like in the analysis of text or speech sequences. 
In simulation processes, the feature is often utilized when the signals from a non fixed number of inputs (i.e. the incoming particles to a volume) must be piled up in a coherent way: the inputs per each particle are presented to the network, with a specific input pattern which may or may not be used to signal the end of the sequence. %A large class of RNNs can be better understood via a process called unrolling, in which the internal memomemory 

\subsection{Generative Models}
\label{subseq:gan}
The networks popular up to 10 years ago were mostly useful during a decision process, such has categorizing inputs (signal vs background, for example) or counting and defining specific regions inside it (segmentation, counting of lesions, etc).

In order to be applied to Monte Carlo simulations, instead, the capability to produce ("generate") an output as close as possible to reality, or to a more standard algorithm. In order to do this, different network topologies and strategies for training are relevant.

%It needs to be highlighted that none of the methods described in this chapter have any intrinsic knowledge of the physics involved in the simulation processes. They are "trained" on external data, which needs to be accurate as possible. While to some extent it is possible to think of a training process using data, in practice the data samples and setups to ensure a generic training is huge, and not easy to obtain in practice. Hence, standard training samples are usually provided via "old school" detailed simulation toolkits, like Geant4~\cite{g4} or FLUKA~\cite{fluka}; it is important to notice that the advent of Machine Learning techniques for Monte Carlo simulations does not imply that the latter will be less needed, on the contrary it will remain fundamental to have  understood and well tuned reference tools to be used to train AI inspired tools.

\subsubsection{Auto-Encoders and Variational Auto-Encoders}
\label{sec:unsupervised}
The autoencoders are a family of unsupervised Neural Networks designed to learn a lower dimensional representation (say N dimensions) out of a set of data (with M dimensions, M\textgreater N). The N dimension representation ("latent space") can be seen as coming from an "understanding" of internal patterns and correlations, and thus as a Neural Network which has been "discovering" these underlying patterns in the input data.

The easiest form of autoencoder is one in which the number of inputs and outputs equals to M, and where there is a layer at dimensionality N. The training is obtained by forcing the network during training to reproduce as close a possible the input features at the output layer, thus requesting the N-dimension space to be as sufficient as possible to represent the M-dimension inputs (see Figure~\ref{fig:autoencoder}).

\begin{figure}[h]
     \centering
     \includegraphics[width=0.95\textwidth]{images/autoencoder.png}
     \caption{An autoencoder in its simplest form.}
     \label{fig:autoencoder}
 \end{figure}
 
 Autoencoders in such form are used for two distinct purposes:
 \begin{itemize}
     \item auto-discover in the inputs hidden symmetries or underlying correlations, which can be used, for example, in lossy compression~\cite{compression} scheme or to drive understanding on the inputs themselves; % https://arxiv.org/abs/1703.00395
     \item since the network is trained on a specific data sample, it will minimize the difference outputs vs inputs on that specific dataset. Once the same network is presented with "different" data, it is expected to fail to reproduce the inputs at the outputs; hence, it can be used to detect anomalous inputs, as important for the detection of not expected features, for example in medical imaging ~\cite{anomalymed} or High Energy Physics events ~\cite{anomalyhep}. 
     % https://arxiv.org/pdf/2004.03271.pdf
     % https://arxiv.org/abs/2005.01598
 \end{itemize}
 
Variational AutoEncoders (VAEs) are autoencoders which can be used to \emph{generate} realistic data, matching as close as possible the  training set. The naive way to generate data from a standard autoencoder is to generate random configurations in the latent space of dimensionality N, and decode it with the rightmost part of Figure~\ref{fig:autoencoder} in order to obtain a M dimensional configuration which is "generated" by the network. In practice, there is no guarantee that the latent space gets organized in a way that all its points are used in the decoding/encoding process. This is where Variational Autoencoders differ: it is explicitly trained in such a way to ensure that the latent space is apt for a generative process.

...
...
...

\subsubsection{Generative Adversarial Networks}
Generative Adversarial Networks (GANs) are a recent~\cite{goodfellow} class of networks designed to reproduce the behaviour of complex systems without an explicit programming.

\begin{figure}[h]
     \centering
     \includegraphics[width=0.95\textwidth]{images/gan.png}
     \caption{The structure of a simple GAN.}
     \label{fig:gan}
 \end{figure}

The method (see Figure~\ref{fig:gan}) implies putting in competition the reference algorithm (or real data, A) with a generative network (B), which produces an output with the same structure and whose response, initially, is random. A second network (C) is trained on the capability to distinguish between the algorithm's output and the generated one. The two networks are put in competition (hence the term \emph{adversarial}), with B winning if it can convince C its response is the real one; in the opposite case, C wins.
The tension between the two networks pushes the network B to generate outputs which are indistinguishable from the real data / the output of the  algorithms. B and C are generic networks, with Convolutional neural structures mostly used.

GANs are more and more used when in the need for replicating the behaviour of a known data source, with improved computing performance. Upon successful training, in fact, the network B has the typical speed of (say) a CNN, and is able to reproduce the output of A, which can be a complex and time consuming algorithm. Successful examples are the capability to reproduce the showering of particles in calorimeters~\cite{atlascalogan, cmscalogan}, the famous generation of realistic faces~\cite{faces}, or for the automatic segmentation of medical images~\cite{ganmed}.

% http://cds.cern.ch/record/2680531/files/ATL-SOFT-PROC-2019-007.pdf
% https://journals.aps.org/prd/pdf/10.1103/PhysRevD.97.014021
% https://arxiv.org/pdf/1807.01954.pdf
% https://thispersondoesnotexist.com/
% https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.13458

\subsubsection{Graph Networks}
In a category of problems, the task is to discover the relations between objects; in the  segmentation of medical images, for example, there is the need to understand whether certain areas are part of a specific organs. Clusterization algorithms in many science realms is another example~\cite{clusterization}.
The most used  network architecture for these use cases is a Graph Neural Network (GNN, \cite{gnn}).
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf
In a GNN, nodes (representing objects) and edges (representing connections between nodes) are the basic entities, and the training process aims to correctly categorize the nodes, while at the same time assessing the strength of each connection.
GNNs are finding large applications in cases where one wants to replace a complex, combinatorial algorithms with a Neural Network: typical examples in literature are Jet clustering in High Energy Physics~\cite{graphclustering}, and tracking in dense particle environments~\cite{graphtracking}.
% https://arxiv.org/abs/2008.06064
% https://arxiv.org/pdf/2003.11603.pdf


