\section{Example of applications for Monte Carlo simulations}
\label{sec:examples}


guardare:

~\cite{Sarrut2018} Sarrut D, Krah N, Létang JM. Generative adversarial networks (GAN) for compact beam source modelling in Monte Carlo simulations. Phys Med Biol 2019;64:215004. https://doi.org/10.1088/1361-6560/ab3fc1.

~\cite{Sarrut2019}
Sarrut D, Krah N, Létang JM. Generative adversarial networks (GAN) for compact beam source modelling in Monte Carlo simulations. Phys Med Biol 2019;64:215004. https://doi.org/10.1088/1361-6560/ab3fc1.

~\cite{Sadeghnejad-Barkousaraie2020}
Sadeghnejad-Barkousaraie A, Bohara G, Jiang S, Nguyen D. A reinforcement learning application of guided Monte Carlo Tree Search algorithm for beam orientation selection in radiation therapy. ArXiv 2020. https://doi.org/10.1088/2632-2153/abe528.

~\cite{Liu2020a} 
Liu CC, Huang HM. A deep learning approach for converting prompt gamma images to proton dose distributions: A Monte Carlo simulation study. Phys Medica 2020;69:110–9. https://doi.org/10.1016/j.ejmp.2019.12.006.

~\cite{Peng2019}
Peng Z, Shan H, Liu T, Pei X, Zhou J, Wang G, et al. Deep learning for accelerating Monte Carlo radiation transport simulation in intensity-modulated radiation therapy. ArXiv 2019:1–8.

\subsection{Emulation of electromagnetic interaction models}




\subsection{Emulation of nuclear interaction models}
Nuclear reactions models are one of the most demanding part of a MC simulation in terms of running time. Despite the large running time, the models already available in MC tool-kits made to develop MC simulation, such as Geant4, have shown severe limitations in reproducing experimental data below 100~MeV/u~\cite{g4-med}. Models developed by theoreticians for this energy domain can be interfaced with Geant4 with good results~\cite{blob-g4}, however their running time is even larger. Ciardiello et al.~\cite{blob-emulation} obtained encouraging preliminary results 
in emulating one of the state-of-the-art models for low energy nuclear reactions with a VAE. The model in question is BLOB (``Boltzmann-Langevin One Body'')~\cite{blob}. BLOB simulates the first part of the nuclear reaction, from the contact of the two nuclei until the energy of the nucleons composing the fragments is balanced among them. The BLOB output is a PDF of finding a nucleon in a position of the phase space. Ciardiello et al. trained a VAE in reproducing the BLOB prediction in the interaction of two $^{12}$C nuclei at 62~MeV/u. For this purpose, they discretized and reduced the dimensionality of the BLOB output to use 3D convolutional layers, already available in the most used libraries for developing Deep Learning applications. In detail, the dimensionality reduction uses the fact that in the reaction in exam BLOB predicts at most three large fragments, i.e. larger than one nucleon. Therefore, they divided the PDF produced by BLOB in three PDFs, one per large fragment, and associated all the nucleon emitted in the first part of the reaction to one of these three large fragments. In this way they used the three colour channels of convolutional layers to represent each of the possible large fragments. In spite of controlling the generative part, they trained a classifier for the event impact parameter ($b$) jointly with the VAE itself. This joint training helps the VAE in learning a the task, given the large sparsity of the input, and force the latent space in being organise with respect to the impact parameter. Moreover, it will be possible to sample from the latent space deciding the impact parameter of each generation.
\autoref{fig:latent} shows that the training events tends to get organised with respect to the impact parameter. \autoref{fig:out} shows that the VAE is able to generate PDFs very similar to the input one when sampling a point nearby the position in the latent space where the input has been encoded.

\begin{figure}[!bht]
\centering
\includegraphics [width=.7\textwidth]{images/latent3}    
\caption{Representation of the VAE latent space described in the text. Each point is the encoding point of one training distribution, the color scale represent the impact parameter of the event.}
\label{fig:latent}
\end{figure}

\begin{figure}[!bht]
\centering
\includegraphics [width=\textwidth]{images/generated}
%\includegraphics [width=.9\columnwidth]{images/cy1}
%\includegraphics [width=.9\columnwidth]{images/cz1}
\caption{Example of results obtained in generating with the VAE a distribution, in red, starting from a point sampled from the neighborhood of the point where the input distribution, in blue, is encoded. The three distributions are the projections on the three axis of 3D PDFs.}
\label{fig:out}
\end{figure}

They conclude their work planning to enlarge the VAE latent space and train the VAE with different projectile energies and using different ions as projectile and target besides interfacing the VAE decoder with Geant4,
 so that it will be possible to use BLOB
 for simulating low energy nuclear interactions without its computational overhead

%\begin{figure}[!bht]
%\centering
%\includegraphics [width=.9\columnwidth]{images/test_reco}
%\caption{Double differential cross sections of alpha particle production in the reaction of $^{12}$C on a thin $^{12}$C target at 62~MeV/u as a function of the kinetic energy of the produced fragment for different angles. The experimental data, in black crosses, are from De Napoli et al.~\cite{DeNapoli:2012bs}. The continuous light blue lines show the BLOB predictions and the dashed magenta lines show the calculated values once encoded to reduce the PDF dimensionality and then decoded back.}
%\label{fig:testreco}
%\end{figure}

\subsection{Emulation of radiation-matter interactions}
\label{subsec:interactions}
%tommaso
% computational cost of full fledged simulations; their not complete ability to match data

DOES THIS GO TO THE INITIAL PART OF THE SECTION???
%CM sono d'accordo a spostare questo paragrafo come primo del capitolo e togliere quello sui modelli EM
One of the most complex tasks in Monte Carlo simulations involving the use of detectors (medical apparatuses, particle physics detectors) lies in the dual need of being able to optimize the design before detector construction, and to simulate the behavior under working conditions after the setup has been prepared.
In both cases, unless the setup is very similar to existing detectors, extensive Monte Carlo simulations of the expected detector capabilities are the widely used solutions. Various such tools exist (Geant4\cite{g4}, Fluka\cite{fluka}, MCNPX\cite{MCNPX}), with different application regimes and specific utilization patterns. As a general rule, these implement iteratively basic radiation-matter low-level processes to a knowledge of the detector setup, including materials, geometry and  XXX; as such, they incur into two general limits:
\begin{itemize}
\item a scarce capability to be tuned to experimental results, by changing the basic modelling of the processes;
\item a large to very large need for computational resources, given the iteration oriented approach and the need to increase the level of iterations in order to obtain a better precision and adherence to data.
\end{itemize}

% Geant4, Fluka, MCNPX: https://doi.org/10.1063/1.2720459

Both limitations can in principle be surpassed via the use of Artificial Intelligence oriented tools.
In presence of experimental data, the response of the AI system can be tuned to that without any explicit modelling of the physics processes; speed can be vastly improved by the change from iterative-based computations to standard Deep Learning matrix algebra, with intrinsic capabilities for high performance processing on, for example, GPU systems.

As an example we want to consider here CaloGan\cite{calogan}, an attempt to reproduce the details of radiation-matter interactions in the complex setup of segmented (3 layers) electromagnetic calorimeters.
A generative Adversarial Network, as those presented in Section~\ref{subsec:gan}, is used in conjunction with an as much-as-accurate as possible Geant4 simulation of the detector setup. The generator side accepts in input input particle 4-momentum, ad after the passage through quite standard convolutional (matching the detector response as 2-D images) and dense layers, the output is compared with Geant4 simulations of a particle with the same parameters.  The training optimizes the energy deposition per layer and per 2-D transverse cell, in a way in principle suited also for using real data in input. Results are very encouraging, even in a detector scenario which can be considered as extreme: not only the quantities of direct training are well reproduced, but also secondary and derived quantities like shower shapes are in most cases well described.

ADD DISCUSSION and PLOT



A second similar attempt, applied to the not-yet existing CLIC proposed electromagnetic and hadronic calorimeter, is presented in~\cite{3dgan}, with the goal to directly reproduce 3-D signals in a high granular calorimeter. The reference dataset, in absence of real data, is has the form of Geant4 generated showers sampled in a 25x25x25 cells around the impinging particle.
% https://doi.org/10.1051/epjconf/201921402010
Figure~\ref{fig:3dgan_shower_longitudinal} shows the longitudinal shower shapes for 100 GeV electrons in the electromagnetic part of the calorimeter compared with detailed Geant4 simulations. The level of agreement is very satisfactory.

In sections~\ref{subsec:speed} and ~\ref{subsec:physical} we will discuss about the speed gain with respect to standard methods, and solutions and needs to prevent unphysical results.

\subsection{Emulation of detector responses}
Monte Carlo tools like Geant4 are designed to simulate, as accurately as possible, the energy deposition (in keV, for example) happening because of the passage on particle / radiation in the material of a detector. In real life, what a scientist measures is instead the response, in forms of analog or digital signals, of a measuring device in which energy deposition is read and processed by some electronics. Hence, in classical systems, the simulation of radiation / matter must be followed by an ad-hoc simulation of the electronic readout system, in order to be compared with actual readings from a detector. In the case of AI inspired tools, this can be avoided by completely bypassing the "energy deposition" output results, and training the system directly with real or realistic (from the above ad-hoc simulation) signals from the electronic back-end. In ~\cite{mri}, for example, images from a real MRI apparatus are used for the training the system (see Figure~\ref{fig:elec}); the use of more classical approaches would be indeed more problematic since there is no practical way to measure (and validate) the output in terms of energy deposition in a running system.

Learning SPECT detector angular response~\cite{Sarrut2018}

\begin{figure}[h]
    \centering

    \includegraphics[width=0.8\textwidth]{images/electronics.png}
    \caption{Difference between classical and AI inspired simulation of experimental setups.}
     \label{fig:elec}

\end{figure}

%ale: trovi tu una referenza decente questo
%tommaso
